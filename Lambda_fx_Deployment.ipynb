{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a8f9e9f-cb2a-4a97-8db6-4574ca188a9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lambda Function Code deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2afe7fd-085d-481a-b433-d32fbdb4a751",
   "metadata": {},
   "source": [
    "Create folder for your deployment package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2808c9-5837-4e36-8779-cb35a6814340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder for your deployment package\n",
    "!mkdir Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadfff79-5a79-45c3-880a-1f4bda9d3f61",
   "metadata": {
    "tags": []
   },
   "source": [
    "Create Lambda python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5628663c-5177-48bd-a126-e0f9e8c50017",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Chatbot/chatbot.py\n",
    "\n",
    "#! /usr/bin/env python\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "import os\n",
    "import requests\n",
    "from requests_aws4auth import AWS4Auth\n",
    "\n",
    "region = os.environ.get('AWS_REGION')\n",
    "bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "aoss_host = os.environ.get('aossHost')\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    if (event['httpMethod'] == 'GET'):\n",
    "        output = load_html()\n",
    "        return {\n",
    "            'statusCode': 200,\n",
    "            'headers': {'Content-Type': 'text/html'},\n",
    "            'body': output\n",
    "        }\n",
    "    elif (event['httpMethod'] == 'POST'):\n",
    "        prompt = event['body']\n",
    "        comm, query = check_prompt_command(prompt)\n",
    "        if comm == 'search':\n",
    "            output = search(query, limit=5)\n",
    "        elif comm == 'rag':\n",
    "            # retrieve the context\n",
    "            info = search(query, limit=5)\n",
    "            # augment the prompt with the context\n",
    "            prompt = 'Use the context below to answer the question:\\n\\n=== Context ===\\n{0}\\n\\n=== Question ===\\n{1}'.format(info, query)\n",
    "            output = chat(prompt)\n",
    "        else:\n",
    "            output = chat(prompt)\n",
    "        return {\n",
    "            'statusCode': 200,\n",
    "            'headers': {'Content-Type': 'text/html'},\n",
    "            'body': output\n",
    "        }\n",
    "    else:\n",
    "         return {\n",
    "            'statusCode': 200,\n",
    "            'headers': {'Content-Type': 'text/html'},\n",
    "            'body': \"OK\"\n",
    "        }\n",
    "\n",
    "def check_prompt_command(prompt):\n",
    "    comm = 'chat'\n",
    "    query = None\n",
    "    # Check the last line of the prompt to see if it is a search request.\n",
    "    lines = prompt.splitlines()\n",
    "    last_line = lines[-1]\n",
    "    # Check if the last line starts with \"Human: \"\n",
    "    if last_line.startswith('Human: '):\n",
    "        last_line = last_line[7:].strip()\n",
    "        # Check if the human prompt starts with \"//search \"\n",
    "        if last_line.startswith('//search '):\n",
    "            query = last_line[9:].strip()\n",
    "            if query != None:\n",
    "                comm = 'search'\n",
    "        # Check if the human prompt starts with \"//rag \"\n",
    "        if last_line.startswith('//rag '):\n",
    "            query = last_line[5:].strip()\n",
    "            if query != None:\n",
    "                comm = 'rag'\n",
    "    return comm, query\n",
    "\n",
    "def load_html():\n",
    "    html = ''\n",
    "    with open('index.html', 'r') as file:\n",
    "        html = file.read()\n",
    "    return html\n",
    "\n",
    "def chat(prompt):\n",
    "    modelId = 'ai21.j2-ultra'\n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "    body=json.dumps({'prompt': prompt, 'maxTokens': 250, 'stopSequences': ['Human:']})\n",
    "    response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept,contentType=contentType)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    completions = response_body['completions']\n",
    "    output = ''\n",
    "    for part in completions:\n",
    "        output += part['data']['text']\n",
    "    return output\n",
    "\n",
    "def search(query, limit=1):\n",
    "    # get embedding\n",
    "    embedding = get_embedding(query)\n",
    "    # prepare for OpenSearch Serverless\n",
    "    service = 'aoss'\n",
    "    credentials = boto3.Session().get_credentials()\n",
    "    awsauth = AWS4Auth(\n",
    "        credentials.access_key, \n",
    "        credentials.secret_key, \n",
    "        region, \n",
    "        service, \n",
    "        session_token=credentials.token\n",
    "    )\n",
    "    # search\n",
    "    index = 'demo-index'\n",
    "    datatype = '_search'\n",
    "    url = aoss_host + '/' + index + '/' + datatype\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    document = {\n",
    "        'size': limit,\n",
    "        'query': {\n",
    "            'knn': {\n",
    "                'embedding': {\n",
    "                    'vector': embedding,\n",
    "                    'k': limit\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    # response\n",
    "    response = requests.get(url, auth=awsauth, json=document, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    output = ''\n",
    "    for item in data['hits']['hits']:\n",
    "        output += item['_source']['content'] + '\\n'\n",
    "    return output.strip()\n",
    "\n",
    "def get_embedding(text):\n",
    "    modelId = 'amazon.titan-embed-text-v1'\n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "    input = {\n",
    "            'inputText': text\n",
    "        }\n",
    "    body=json.dumps(input)\n",
    "    response = bedrock.invoke_model(\n",
    "        body=body, modelId=modelId, accept=accept,contentType=contentType)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    embedding = response_body['embedding']\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c499aa-9fb0-4086-82ff-975747fc4c6c",
   "metadata": {},
   "source": [
    "For all GET requests, we load the HTML content from index.html and returns it to the requester.\n",
    "\n",
    "For all POST requests, we extract the body from the request, then\n",
    "\n",
    "If the last line from human starts with //search, this is treated as a search command, anything after the //search command is treated as the query text. In this case, we convert the query text into embedding, then search in the knowledge base. The 5 closest data entry in the knowledge base is returned to the requester.\n",
    "\n",
    "If the last line from human starts with //rag, this is treated as a request for RAG. Anything after the //rag command is treated as the query text. In this case, we convert the query text into embedding, retrieve 5 most relevant entries from the knowledge base, augment the prompt with the context, invoke the foundation model with the augmented prompt and return the response to the requester.\n",
    "\n",
    "Otherwise, we use the request body as the prompt to invoke a foundation model, then return the response from the foundation model to the requester.\n",
    "\n",
    "For all other requests, we simply return an OK to the requester."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e83339-7de3-4104-b7da-10e8e92d333e",
   "metadata": {},
   "source": [
    "# Deployment package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e732d1-9c27-4923-bcbb-23bc9a9e6c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ~/Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e77a2e-03d0-4385-b507-af81ccea3c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all dependency python packages\n",
    "!pip install --target ./package requests --no-deps\n",
    "!pip install --target ./package requests_aws4auth --no-deps\n",
    "!pip install --target ./package charset_normalizer --no-deps\n",
    "!pip install --target ./package idna --no-deps\n",
    "!pip install --target ./package certifi --no-deps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2effea7f-5b58-4e05-b397-87baa74b3abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm my_deployment_package.zip\n",
    "!cd package\n",
    "!zip -r ../my_deployment_package.zip .\n",
    "!cd ..\n",
    "# zip the file you needed on top of dependency python packages\n",
    "!zip my_deployment_package.zip index.html\n",
    "!zip my_deployment_package.zip chatbot.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4966cf18-d745-4da5-bfdb-bedfbdd0dc90",
   "metadata": {},
   "source": [
    "Have S3 bucket with name \"your-s3-bucket-name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c30630-584e-424a-92dc-161fae58c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the deployment package to S3 with name \"your-s3-bucket-name\"\n",
    "\n",
    "S3_BUCKET=\"your-s3-bucket-name\"\n",
    "!aws s3 cp my_deployment_package.zip s3://$S3_BUCKET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b1fba1-c22d-42be-8f2a-7e4d236ea4d3",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "Now we need to configure the Lambda function \"YourLambdaFunctionName\" to use the new deployment package:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59dcb5b-f32f-4ba1-94d8-72bcd9e4c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws lambda update-function-code --function-name YourLambdaFunctionName --s3-bucket $S3_BUCKET --s3-key my_deployment_package.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2628b183-6243-4d19-ba05-42ad9f52fc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws lambda update-function-configuration --function-name YourLambdaFunctionName --handler chatbot.lambda_handler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe20242-a49e-4626-ba02-f49191922290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
